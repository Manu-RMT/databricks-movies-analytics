{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "949d8b5f-a707-4bb5-b22b-2736f8f8eeca",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "autoreload"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0becef2e-aa80-4244-9eb8-45ae1a07ccdc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "chargement bibliothèque"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/Workspace/Users/mandu543@gmail.com/databricks-movies-analytics/Movies_Project\")\n",
    "\n",
    "# Maintenant on peut importer\n",
    "from src.utils import *\n",
    "\n",
    "# Liste tous les schemas du catalog 'workspace'\n",
    "spark.sql(\"SHOW SCHEMAS IN workspace\").show()\n",
    "\n",
    "print(VOLUME_PATH)\n",
    "print(BRONZE_TABLE)\n",
    "print(CSV_EXTENSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c54f0a8c-1094-458c-8e57-fd2adab00da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ingestion des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "491dda55-2d24-4786-9a61-d4f417943c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#RQ : Pout utiliser : %run  faut transformer les fichiers config et transformation en notebook\n",
    "#%run /Users/mandu543@gmail.com/Movies_Project/src/config\n",
    "#%run /Workspace/Users/mandu543@gmail.com/Movies_Project/scr/transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40792d1-8cd8-4cef-a11a-b586070b955e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Récupération des fichiers et insertion dans le couche bronze (tmdb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de831fb-923a-47f5-81cb-5b81e966cdb4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "lectures csv source"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Lister tous les fichiers CSV du Volume\n",
    "# -----------------------------\n",
    "csv_files = [f.path for f in dbutils.fs.ls(VOLUME_PATH) if f.name.endswith(CSV_EXTENSION)]\n",
    "print(f\"Fichiers CSV trouvés : {csv_files}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Lire tous les CSV avec options sécurisées\n",
    "# -----------------------------\n",
    "# Lire CSV avec première ligne comme header\n",
    "# Gérer les champs multi-lignes, guillemets, virgules et espaces inutiles\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = spark.read \\\n",
    "            .option(\"header\", True) \\\n",
    "            .option(\"multiLine\", True) \\\n",
    "            .option(\"escape\", '\"') \\\n",
    "            .option(\"quote\", '\"') \\\n",
    "            .option(\"ignoreLeadingWhiteSpace\", True) \\\n",
    "            .csv(file)\n",
    "dfs.append(df)\n",
    "# -----------------------------\n",
    "# Combiner tous les CSV\n",
    "# -----------------------------\n",
    "df_bronze = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    df_bronze = df_bronze.unionByName(df)\n",
    "# Create schema if not exists\n",
    "spark.sql(\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS {BRONZE_TABLE.split('.')[1]}\"\n",
    ")\n",
    "# Écriture Delta Bronze\n",
    "df_bronze.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_TABLE)\n",
    "\n",
    "print(f\"✅ Bronze table created with {df_bronze.count()} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e74dc4b5-b5af-416e-acaa-6d492af9f489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Voir les versions des insertions grâce au format delta\n",
    "\n",
    "Meme si overwrite fait un truncate, le format delta peut récupérer des versions et restaurer les versions souhaitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa5e4dcc-b3db-4f61-b782-0ad65f4b1765",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Version format delta"
    }
   },
   "outputs": [],
   "source": [
    "# Voir versions\n",
    "spark.sql(\"DESCRIBE HISTORY \"+BRONZE_TABLE+\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f1aa820-3d83-4cbe-a8f7-e4c5cffe2392",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rollback version"
    }
   },
   "outputs": [],
   "source": [
    "# Lire version précédente\n",
    "#df_prev = spark.read.format(\"delta\").option(\"versionAsOf\", 0).table(\"workspace.bronze.tmdb_movies\")\n",
    "\n",
    "# Restaurer table\n",
    "#df_prev.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.bronze.tmdb_movies\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_bronze_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
